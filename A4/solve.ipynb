{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphframes in c:\\users\\krish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\krish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from graphframes) (1.26.2)\n",
      "Requirement already satisfied: nose in c:\\users\\krish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from graphframes) (1.3.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install graphframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pyspark --packages graphframes:graphframes:0.8.2-spark3.0-s_2.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GraphFramesExample\") \\\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from graphframes import GraphFrame\n",
    "edges = spark.read.csv(\"musae_git_edges.csv\", header=True, inferSchema=True)\n",
    "edges = edges.withColumnRenamed(\"id_1\", \"src\").withColumnRenamed(\"id_2\", \"dst\")\n",
    "\n",
    "vertices = spark.read.csv(\"musae_git_target.csv\", header=True, inferSchema=True)\n",
    "vertices = vertices.withColumnRenamed(\"id\", \"id\").select(\"id\", \"name\", \"ml_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "graph = GraphFrame(vertices, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+---------+-----+\n",
      "|   id|            name|ml_target|label|\n",
      "+-----+----------------+---------+-----+\n",
      "|37268|        Chloejay|        0|35773|\n",
      "|19021|AntoinedeChassey|        0|35773|\n",
      "|28730|      aakashlpin|        0|35773|\n",
      "|23776|    eroispaziali|        0| 5547|\n",
      "|31037|             dok|        0|35773|\n",
      "|34207|        pixeline|        0|35773|\n",
      "|29127|   geonwoo-jeong|        0|35773|\n",
      "| 9831|        ekntrtmz|        0|35773|\n",
      "| 5354|       cbarcenas|        0|35773|\n",
      "|32676|          sasha0|        0|35773|\n",
      "| 4926|   dustinmoorman|        0|35773|\n",
      "|29270|      advaitsave|        1| 5547|\n",
      "|14609|      huangjihua|        0|31126|\n",
      "|21377|    martinyunify|        1|35773|\n",
      "|11852|  JeroenReumkens|        0|35773|\n",
      "| 8390|        diegonvs|        0|35773|\n",
      "|28761|        sosedoff|        0|35773|\n",
      "|10837|    lch14forever|        1|26963|\n",
      "| 4992|        eirslett|        0|35773|\n",
      "|20894|         fakyras|        1|35773|\n",
      "+-----+----------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpa_result = graph.labelPropagation(maxIter=5)\n",
    "lpa_result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities=lpa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, lit, when\n",
    "\n",
    "edges_with_communities = edges\\\n",
    "    .join(lpa_result.selectExpr(\"id as src\", \"label as src_label\"), on=\"src\") \\\n",
    "    .join(lpa_result.selectExpr(\"id as dst\", \"label as dst_label\"), on=\"dst\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_edges = edges_with_communities.filter(col(\"src_label\") == col(\"dst_label\"))\n",
    "\n",
    "total_edges = edges.count()\n",
    "intra_community_edges = intra_edges.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity Score: 0.7995557139545264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modularity = intra_community_edges / total_edges\n",
    "print(f\"Modularity Score: {modularity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
